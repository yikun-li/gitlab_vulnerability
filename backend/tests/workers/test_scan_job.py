import pytest
from unittest.mock import patch
import asyncio
from aioresponses import aioresponses
from sqlalchemy.orm import Session
from faker import Faker
from urllib.parse import quote
from datetime import datetime

from app.config.app import settings
from app.database.models.detection import Job
from app.database.schemas.gitlab import FileContent
from app.database.schemas.workers_status import StatusScanJob
from app.database.crud.workers_status import get_status_scan_job_by_db_job_id
from app.internal.gitlab import STAGES
from app.workers import scan_job

from tests.factories.detection import JobFactory
from tests.utils.assertion import assert_attributes

@pytest.mark.asyncio
async def test_start_success(mock_aioresponse: aioresponses, testing_db_session: Session, TestingSessionLocal: Session):
  fake = Faker()
  job = JobFactory()
  headers = {"Authorization": f'Bearer {settings.GITLAB_ACCESS_TOKEN}'}

  files: list[FileContent] = [
    FileContent(path=file_path, content=fake.sentence(nb_words=10).encode('utf-8')) for file_path in job.diff
  ]
  for data in files:
    encoded_file_path = quote(data.path, safe='')
    get_files_url = f"{settings.GITLAB_BASE_API_URL}/{job.gl_project_id}/repository/files/{encoded_file_path}/raw?ref={job.gl_commit_sha}"
    mock_aioresponse.get(
      get_files_url,
      headers=headers,
      status=200,
      body=data.content
    )

  new_job_id = fake.random_int()
  retrieve_job_url = f"{settings.GITLAB_BASE_API_URL}/{job.gl_project_id}/pipelines/{job.gl_pipeline_id}/jobs"
  mock_aioresponse.get(
    retrieve_job_url, 
    headers=headers,
    status=200,
    payload=[
      {"name": STAGES.VULNERABILITY_SCAN, "id": fake.random_int()},
      {"name": STAGES.REPORT_RETRIEVAL, "id": new_job_id},
    ]
  )

  artifact_retrieval_url = f"{settings.GITLAB_BASE_API_URL}/{job.gl_project_id}/jobs/{new_job_id}/play"
  mock_aioresponse.post(artifact_retrieval_url, headers=headers, status=200)

  with patch('asyncio.sleep', return_value=asyncio.Future()) as mock_sleep:
    success = await scan_job.start(db_job_id=job.id, session=TestingSessionLocal)
  db_job = testing_db_session.query(Job).filter(Job.id == job.id).one_or_none()
  
  assert success
  assert hasattr(db_job, "security_report")
  assert db_job.security_report is not None
  
  status_scan_job_attrs = {
    "db_get_job_task": "success",
    "gitlab_get_related_files_task": "success",
    "scan_run_task": "success",
    "db_create_and_save_task": "success",
    "gitlab_trigger_job_task": "success",
    "overall_status": "success",
    "remarks": None,
  }
  db_status_scan_job = StatusScanJob.model_validate(
    get_status_scan_job_by_db_job_id(db=testing_db_session, db_job_id=job.id)
  )
  assert_attributes(db_object=db_status_scan_job, attrs=status_scan_job_attrs, excl=["job", "job_id"])

@pytest.mark.asyncio
async def test_start_get_related_files_failure(mock_aioresponse: aioresponses, testing_db_session: Session, TestingSessionLocal: Session):
  fake = Faker()
  job = JobFactory()
  headers = {"Authorization": f'Bearer {settings.GITLAB_ACCESS_TOKEN}'}

  files: list[FileContent] = [
    FileContent(path=file_path, content=fake.sentence(nb_words=10).encode('utf-8')) for file_path in job.diff
  ]
  for data in files:
    encoded_file_path = quote(data.path, safe='')
    get_files_url = f"{settings.GITLAB_BASE_API_URL}/{job.gl_project_id}/repository/files/{encoded_file_path}/raw?ref={job.gl_commit_sha}"
    mock_aioresponse.get(
      get_files_url,
      headers=headers,
      status=400,
      body=data.content
    )
  
  with patch('app.internal.model.run') as mock_model:
    success = await scan_job.start(db_job_id=job.id, session=TestingSessionLocal)
    mock_model.assert_not_called()
  db_job = testing_db_session.query(Job).filter(Job.id == job.id).one_or_none()

  assert not success
  assert db_job.security_report is None
  
  status_scan_job_attrs = {
    "db_get_job_task": "success",
    "gitlab_get_related_files_task": "failure",
    "scan_run_task": "not_started",
    "db_create_and_save_task": "not_started",
    "gitlab_trigger_job_task": "not_started",
    "overall_status": "failure",
    "remarks": "failed to retrieve relevant files from gitlab",
  }
  db_status_scan_job = StatusScanJob.model_validate(
    get_status_scan_job_by_db_job_id(db=testing_db_session, db_job_id=job.id)
  )
  assert_attributes(db_object=db_status_scan_job, attrs=status_scan_job_attrs, excl=["job", "job_id"])

@pytest.mark.asyncio
async def test_start_scan_run_failure(mock_aioresponse: aioresponses, testing_db_session: Session, TestingSessionLocal: Session):
  fake = Faker()
  job = JobFactory()
  headers = {"Authorization": f'Bearer {settings.GITLAB_ACCESS_TOKEN}'}

  files: list[FileContent] = [
    FileContent(path=file_path, content=fake.sentence(nb_words=10).encode('utf-8')) for file_path in job.diff
  ]
  for data in files:
    encoded_file_path = quote(data.path, safe='')
    get_files_url = f"{settings.GITLAB_BASE_API_URL}/{job.gl_project_id}/repository/files/{encoded_file_path}/raw?ref={job.gl_commit_sha}"
    mock_aioresponse.get(
      get_files_url,
      headers=headers,
      status=200,
      body=data.content
    )
  
  with patch('app.internal.model.run', return_value=(False, None, None, None, None, None, None)), \
      patch('app.internal.report.create_and_save') as mock_create_and_save:
    success = await scan_job.start(db_job_id=job.id, session=TestingSessionLocal)
    mock_create_and_save.assert_not_called()
  db_job = testing_db_session.query(Job).filter(Job.id == job.id).one_or_none()

  assert not success
  assert db_job.security_report is None
  
  status_scan_job_attrs = {
    "db_get_job_task": "success",
    "gitlab_get_related_files_task": "success",
    "scan_run_task": "failure",
    "db_create_and_save_task": "not_started",
    "gitlab_trigger_job_task": "not_started",
    "overall_status": "failure",
    "remarks": "failed to run model",
  }
  db_status_scan_job = StatusScanJob.model_validate(
    get_status_scan_job_by_db_job_id(db=testing_db_session, db_job_id=job.id)
  )
  assert_attributes(db_object=db_status_scan_job, attrs=status_scan_job_attrs, excl=["job", "job_id"])

@pytest.mark.asyncio
async def test_start_create_and_save_failure(mock_aioresponse: aioresponses, testing_db_session: Session, TestingSessionLocal: Session):
  fake = Faker()
  job = JobFactory()
  headers = {"Authorization": f'Bearer {settings.GITLAB_ACCESS_TOKEN}'}

  files: list[FileContent] = [
    FileContent(path=file_path, content=fake.sentence(nb_words=10).encode('utf-8')) for file_path in job.diff
  ]
  for data in files:
    encoded_file_path = quote(data.path, safe='')
    get_files_url = f"{settings.GITLAB_BASE_API_URL}/{job.gl_project_id}/repository/files/{encoded_file_path}/raw?ref={job.gl_commit_sha}"
    mock_aioresponse.get(
      get_files_url,
      headers=headers,
      status=200,
      body=data.content
    )
  
  with patch('app.internal.report.create_and_save', return_value=(False, None)), \
      patch('app.internal.gitlab.trigger_job') as mock_trigger_job:
    success = await scan_job.start(db_job_id=job.id, session=TestingSessionLocal)
    mock_trigger_job.assert_not_called()
  db_job = testing_db_session.query(Job).filter(Job.id == job.id).one_or_none()

  assert not success
  assert db_job.security_report is None
  
  status_scan_job_attrs = {
    "db_get_job_task": "success",
    "gitlab_get_related_files_task": "success",
    "scan_run_task": "success",
    "db_create_and_save_task": "failure",
    "gitlab_trigger_job_task": "not_started",
    "overall_status": "failure",
    "remarks": "failed to generate and save security report",
  }
  db_status_scan_job = StatusScanJob.model_validate(
    get_status_scan_job_by_db_job_id(db=testing_db_session, db_job_id=job.id)
  )
  assert_attributes(db_object=db_status_scan_job, attrs=status_scan_job_attrs, excl=["job", "job_id"])

@pytest.mark.asyncio
async def test_start_trigger_job_failure(mock_aioresponse: aioresponses, testing_db_session: Session, TestingSessionLocal: Session):
  fake = Faker()
  job = JobFactory()
  headers = {"Authorization": f'Bearer {settings.GITLAB_ACCESS_TOKEN}'}

  files: list[FileContent] = [
    FileContent(path=file_path, content=fake.sentence(nb_words=10).encode('utf-8')) for file_path in job.diff
  ]
  for data in files:
    encoded_file_path = quote(data.path, safe='')
    get_files_url = f"{settings.GITLAB_BASE_API_URL}/{job.gl_project_id}/repository/files/{encoded_file_path}/raw?ref={job.gl_commit_sha}"
    mock_aioresponse.get(
      get_files_url,
      headers=headers,
      status=200,
      body=data.content
    )
  
  new_job_id = fake.random_int()
  retrieve_job_url = f"{settings.GITLAB_BASE_API_URL}/{job.gl_project_id}/pipelines/{job.gl_pipeline_id}/jobs"
  mock_aioresponse.get(
    retrieve_job_url, 
    headers=headers,
    status=400,
  )

  artifact_retrieval_url = f"{settings.GITLAB_BASE_API_URL}/{job.gl_project_id}/jobs/{new_job_id}/play"
  mock_aioresponse.post(artifact_retrieval_url, headers=headers, status=200)

  success = await scan_job.start(db_job_id=job.id, session=TestingSessionLocal)
  db_job = testing_db_session.query(Job).filter(Job.id == job.id).one_or_none()

  assert not success
  assert db_job.security_report is not None
  
  status_scan_job_attrs = {
    "db_get_job_task": "success",
    "gitlab_get_related_files_task": "success",
    "scan_run_task": "success",
    "db_create_and_save_task": "success",
    "gitlab_trigger_job_task": "failure",
    "overall_status": "failure",
    "remarks": "failed to trigger artifact retrieval job in gitlab",
  }
  db_status_scan_job = StatusScanJob.model_validate(
    get_status_scan_job_by_db_job_id(db=testing_db_session, db_job_id=job.id)
  )
  assert_attributes(db_object=db_status_scan_job, attrs=status_scan_job_attrs, excl=["job", "job_id"])